# -*- coding: utf-8 -*-
"""ML_TERAPAN_ML_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Q4Z2YNGMyA1GbVoz7UNeTvv1xU221qGC

# Proyek: Predictive Analytic - Klasifikasi Diabetes

Nama: : Jessica Theresia<br>
Email: : me.jessicatheresia@gmail.com<br>
ID Dicoding: : jessica_trs<br>

# Import Library
"""

# Install library

from google.colab import drive
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression

"""# Load Data

Dataset yang digunakan adalah Healthcare Diabetes Dataset dari Kaggle yang dapat diunduh di sini https://www.kaggle.com/datasets/nanditapore/healthcare-diabetes. Dataset erdiri dari 2768 baris dan 10 kolom fitur.
"""

# Mount Google Drive
drive.mount('/content/drive')

# Memuat dataset
df = pd.read_csv("/content/drive/MyDrive/Dicoding ML Submission/ML Terapan/Healthcare-Diabetes.csv")

# Menampilkan 5 baris pertama
print("First 5 records:")
print(df.head())

"""# Exploratory Data Analysis (EDA)

## Info Data
"""

print("Informasi Dataset:")
print(df.info())

# Statistik deskriptif
print("\nStatistik Deskriptif:")
print(df.describe())

"""## Checking Missing Value"""

# Cek jumlah missing value
print("\nJumlah Missing Value per Kolom:")
print(df.isnull().sum())

"""## Checking Outliers"""

# Menggunakan IQR method
Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))
outliers.sum()

# Visualisasi boxplot semua fitur numerik (kecuali 'Outcome')
numerical_features = df.drop('Outcome', axis=1).columns
plt.figure(figsize=(15, 10))

for i, col in enumerate(numerical_features):
    plt.subplot(3, 3, i+1)
    sns.boxplot(data=df[col])
    plt.title(f'Boxplot of {col}')

plt.tight_layout()
plt.show()

"""## Univariate Analysis

Dilakukan pengecekan distirbusi data pada setiap atribut numerik
"""

# Plot histogram untuk setiap kolom numerik
plt.figure(figsize=(15, 10))
for i, col in enumerate(df.columns[:-1]):  # Kecuali Outcome
    plt.subplot(3, 3, i + 1)
    sns.histplot(df[col], kde=True, bins=30, color='skyblue')
    plt.title(f'Distribution of {col}')

plt.tight_layout()
plt.show()

"""**Insight

EDA menunjukkan beberapa kolom memiliki nilai 0 yang tidak realistis, seperti Glucose, BloodPressure, dan BMI. Visualisasi histogram dan boxplot juga menunjukkan adanya outlier.

## Bivariate Analysis
"""

sns.set_palette("pastel")
df['Outcome'].value_counts().plot(kind="pie", autopct="%1.1f%%")
plt.title("Percentage of Diabetes vs Non Diabetes")
plt.show()

"""Dari visualisasi data diatas, dapat disimpulkan bahwa data diabetes dan non diabetes imbalance."""

# Visualisasikan pairwise relationship
sns.pairplot(df, hue='Outcome', diag_kind='kde', palette='coolwarm')
plt.suptitle('Pairplot Fitur vs Outcome', y=1.02)
plt.show()

"""## Multivariate Analysis

Korelasi antar fitur terhadap target Outcome:
"""

# Korelasi antar variabel
plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

"""Dari heatmap dapat dilihat bahwa Glucose, BMI, dan Age menunjukkan korelasi positif yang kuat dengan Outcome.

Variabel seperti Skin Thickness atau Insulin memiliki korelasi lebih lemah, namun tetap relevan secara klinis.

# Data Preprocessing

## Hapus kolom yang tidak relevan
"""

df = df.drop('Id', axis=1)

print(df.columns)

"""## Handling Missing Value

Nilai 0 pada kolom medis diganti dengan NaN, lalu dilakukan imputasi median.
"""

# Kolom-kolom yang tidak seharusnya memiliki nilai 0
cols_with_zero = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']

# Ganti nilai 0 dengan NaN
df[cols_with_zero] = df[cols_with_zero].replace(0, np.nan)

print("Jumlah Missing Value (setelah diganti dari nilai 0):")
print(df[cols_with_zero].isnull().sum())

# Isi missing value dengan nilai median
for col in cols_with_zero:
    median_value = df[col].median()
    df[col].fillna(median_value, inplace=True)

print("\nCek missing setelah imputasi:")
print(df.isnull().sum())

"""## Handling Outliers"""

# Winsorizing dengan IQR
for col in df.columns:
    if col != 'Outcome':
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR
        df[col] = np.where(df[col] < lower_bound, lower_bound,
                  np.where(df[col] > upper_bound, upper_bound, df[col]))

Q1 = df.quantile(0.25)
Q3 = df.quantile(0.75)
IQR = Q3 - Q1

outliers = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))
outlier_count = outliers.sum().sort_values(ascending=False)

print("Jumlah akhir outlier per kolom:")
print(outlier_count)

# Simpan dataset bersih
df.to_csv("/content/drive/MyDrive/Dicoding ML Submission/ML Terapan/Cleaned_Healthcare_Diabetes.csv", index=False)

print("Dataset telah disimpan ke Google Drive sebagai Cleaned_Healthcare_Diabetes.csv")

"""## Split Data

Dataset dibagi menjadi 80% data pelatihan dan 20% data pengujian.
"""

X = df.drop('Outcome', axis=1)
y = df['Outcome']

# Split data: 80% training, 20% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("Ukuran data latih:", X_train.shape)
print("Ukuran data uji:", X_test.shape)

"""## Normalisasi Data

Normalisasi menggunakan StandardScaler agar semua fitur berada pada skala yang sama.
"""

# Inisialisasi scaler
scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## Handling Imbalance"""

print("Distribusi kelas sebelum SMOTE:")
print(y_train.value_counts(normalize=True))

"""Menggunakan SMOTE untuk menangani ketidakseimbangan data pada kelas target."""

smote = SMOTE(random_state=42)

X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)

print("Distribusi kelas setelah SMOTE:")
print(y_train_resampled.value_counts(normalize=True))

"""# Modeling

## Train w/ Basic Models

### 1. KNN


- Berdasarkan jarak antara titik data.
- Kelebihan: Tidak memerlukan pelatihan.
- Kekurangan: Sensitif terhadap noise dan ukuran data.
"""

# Inisialisasi dan latih model KNN
knn_model = KNeighborsClassifier(n_neighbors=15, weights='distance')
knn_model.fit(X_train_resampled, y_train_resampled)

# Prediksi pada data uji
y_pred_knn = knn_model.predict(X_test_scaled)

"""### 2. Random Forest

- Ensembel dari pohon keputusan.
- Kelebihan: Akurasi tinggi, robust terhadap outlier.
- Kekurangan: Kurang interpretatif.
"""

# Inisialisasi dan latih model Random Forest
rf_model = RandomForestClassifier(n_estimators=100, random_state=101)
rf_model.fit(X_train_resampled, y_train_resampled)

# Prediksi pada data uji
y_pred_rf = rf_model.predict(X_test_scaled)

"""### Logistic Regression

- Model dasar klasifikasi biner yang memberikan probabilitas suatu kelas.
- Kelebihan: Sederhana, interpretatif.
- Kekurangan: Kurang kuat untuk hubungan non-linear.
"""

# Latih model Logistic Regression
log_model = LogisticRegression(max_iter=1000)
log_model.fit(X_train_resampled, y_train_resampled)

# Prediksi pada data uji
y_pred_log = log_model.predict(X_test_scaled)

"""### Accuracy (before tuning)"""

print("=== Evaluasi Akurasi Ketiga Model ===")
print("Accuracy KNN :", accuracy_score(y_test, y_pred_knn))
print("Accuracy Random Forest :", accuracy_score(y_test, y_pred_rf))
print("Accuracy Logistic Regression :", accuracy_score(y_test, y_pred_log))

"""# Hyperparameter Tuning untuk KNN

Walaupun akurasi Model KNN sudah baik namun masih dapat dilakukan hyperparameter tuning karena :

1. KNN sangat sensitif terhadap pilihan hyperparameter seperti:

- n_neighbors (jumlah tetangga terdekat):

  Terlalu kecil bisa membuat model terlalu sensitif terhadap noise (overfitting), terlalu besar bisa membuat model terlalu general (underfitting).
- weights (uniform vs distance):

  Memberi bobot lebih pada tetangga terdekat bisa meningkatkan performa jika data tidak tersebar merata.
- metric (cara hitung jarak):

  Euclidean, Manhattan, atau Minkowski bisa berdampak besar pada bagaimana jarak dihitung dan prediksi dilakukan, tergantung karakteristik data.
<br>

2. Tuning diperlukan agar model bisa menemukan kombinasi parameter yang membuat prediksi paling akurat dan seimbang antara precision dan recall.
<br>

3. Meskipun akurasi awal sudah tinggi, tuning meningkatkan performa keseluruhan terutama pada metrik lain seperti F1-score.
"""

from sklearn.model_selection import GridSearchCV

# Definisikan parameter grid untuk KNN
param_grid_knn = {
    'n_neighbors': list(range(3, 21, 2)),
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

# Inisialisasi model KNN
knn = KNeighborsClassifier()

# Grid search dengan 5-fold cross-validation, scoring berdasarkan f1 untuk klasifikasi seimbang
grid_search_knn = GridSearchCV(estimator=knn,
                               param_grid=param_grid_knn,
                               scoring='f1',
                               cv=5,
                               n_jobs=-1,
                               verbose=1)

# Fit grid search ke data training yang sudah di-resample
grid_search_knn.fit(X_train_resampled, y_train_resampled)

# Cetak hasil terbaik
print("Best parameters for KNN:", grid_search_knn.best_params_)

# model terbaik
best_knn = grid_search_knn.best_estimator_

y_pred_best_knn = best_knn.predict(X_test_scaled)

"""# Hyperparameter Tuning untuk Logistic Regression

Walaupun akurasi Model Logistic Regression sudah baik namun masih dapat dilakukan hyperparameter tuning karena :
1. Logistic Regression juga punya hyperparameter penting, terutama saat menggunakan regularisasi:
- penalty (jenis regularisasi seperti L1, L2, ElasticNet):
  
  Membantu mencegah overfitting dan memilih fitur yang relevan.
- solver:

  Algoritma optimasi yang berbeda cocok untuk konfigurasi penalty tertentu dan ukuran dataset.
- l1_ratio (porsi regularisasi L1 dan L2 saat penalty ElasticNet digunakan):
  
  Memberi keseimbangan antara sparsity dan shrinkage.
  
<br>

2. Tuning penting karena:

- Model dasar tanpa regularisasi yang tepat bisa underfit atau overfit.
- Memilih regularisasi yang tepat dan solver yang cocok dapat meningkatkan performa terutama pada data yang mungkin memiliki fitur korelasi atau noise.
- Dalam kasus ini, meski akurasi tidak meningkat signifikan, tuning dimaksudkan untuk meningkatkan keseimbangan precision dan recall.
"""

# Parameter grid
param_grid = {
    'penalty': ['elasticnet'],
    'solver': ['saga'],
    'l1_ratio': [0.1, 0.5, 0.9]
}

# Inisialisasi model
lr = LogisticRegression(max_iter=1000, random_state=42)

# Grid search
grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, scoring='f1', cv=5, n_jobs=-1)
grid_search.fit(X_train_resampled, y_train_resampled)

# Model terbaik
best_lr = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

y_pred_best_lr = best_lr.predict(X_test_scaled)

"""# Hyperparameter Tuning untuk Random Forest

Akurasi Model RF masih terlihat rendah maka perlu dilakukan hyperparameter tuning dan berikut beberapa pertimbangannya :

1. Random Forest memiliki banyak hyperparameter yang berpengaruh, seperti:
- n_estimators (jumlah pohon): Jumlah pohon yang lebih banyak bisa meningkatkan akurasi tapi juga meningkatkan waktu komputasi.
- max_depth (kedalaman maksimal pohon): Membatasi kedalaman dapat mengurangi overfitting.
- min_samples_split dan min_samples_leaf: Mengontrol seberapa banyak data minimum untuk membagi node, mempengaruhi kompleksitas model.
- max_features: Memilih fitur yang digunakan untuk tiap split, mempengaruhi variasi antar pohon dan overfitting.

2. Tuning bertujuan mendapatkan kombinasi parameter yang paling baik untuk menjaga keseimbangan antara bias dan variance, serta mengoptimalkan akurasi sekaligus generalisasi model.
"""

# Parameter grid
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt']
}

# Inisialisasi model
rf = RandomForestClassifier(random_state=42)

# Grid search
grid_search_rf = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    scoring='f1',
    cv=5,
    n_jobs=-1,
    verbose=2
)

# Fit model
grid_search_rf.fit(X_train_resampled, y_train_resampled)

# Model terbaik
best_rf_model = grid_search_rf.best_estimator_
print("Best Parameters RF:", grid_search_rf.best_params_)

y_pred_best_rf = best_rf_model.predict(X_test_scaled)

"""# Evaluations (after tuning)

Metrik yang digunakan:

- Accuracy = (TP + TN) / Total
- Precision = TP / (TP + FP)
- Recall = TP / (TP + FN)
- F1-Score = 2 * (Precision * Recall) / (Precision + Recall)
"""

# Evaluasi Akhir Model KNN
print("=== Evaluasi Model KNN (Tuned) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best_knn))
print("Precision:", precision_score(y_test, y_pred_best_knn))
print("Recall   :", recall_score(y_test, y_pred_best_knn))
print("F1-score :", f1_score(y_test, y_pred_best_knn))
print("\nClassification Report:\n", classification_report(y_test, y_pred_best_knn))

# Evaluasi Akhir Model Random Forest
print("=== Evaluasi Random Forest (Tuned) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best_rf))
print("Precision:", precision_score(y_test, y_pred_best_rf))
print("Recall   :", recall_score(y_test, y_pred_best_rf))
print("F1-score :", f1_score(y_test, y_pred_best_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_best_rf))

# Evaluasi Akhir Model Logistic Regression
print("=== Evaluasi Model Logistic Regression (Tuned) ===")
print("Accuracy :", accuracy_score(y_test, y_pred_best_lr))
print("Precision:", precision_score(y_test, y_pred_best_lr))
print("Recall   :", recall_score(y_test, y_pred_best_lr))
print("F1-score :", f1_score(y_test, y_pred_best_lr))
print("\nClassification Report:\n", classification_report(y_test, y_pred_best_lr))

"""** Insight

**KNN** menjadi model yang direkomendasikan dari ketiga model karena menghasilkan nilai akurasi, precision, recall, dan F1-score terbaik serta paling seimbang di antara ketiganya, hampir semua kasus positif (penyakit) berhasil dideteksi dengan benar. Artinya, model tidak melewatkan satu pun pasien yang benar-benar mengidap diabetes dalam prediksinya (False Negative = 0). Hal ini sangat penting dalam konteks medis, karena salah satu tujuan utama adalah mendeteksi semua kasus positif secara tepat.

# Save Model
"""

joblib.dump(knn_model, 'best_knn_model.pkl')

joblib.dump(best_rf_model, 'best_rf_model.pkl', protocol=4)

joblib.dump(best_lr, 'best_lr_model.pkl', protocol=4)

joblib.dump(scaler, 'scaler.pkl')

"""# Testing

streamlit webApp : https://predictive-analytic-diabetes.streamlit.app/

github repo : https://github.com/Jejetrs/Predictive-Analytic---Diabetes.git
"""